7767517
196 196
pnnx.Input               pnnx_input_0             0 1 0 #0=(1,3,256,256)f32
pnnx.Attribute           pnnx_4                   0 1 1 @pnnx_4=(64,64,1)f32 #1=(64,64,1)f32
pnnx.Attribute           pnnx_5                   0 1 2 @pnnx_5=(64,64,1)f32 #2=(64,64,1)f32
pnnx.Attribute           pnnx_9                   0 1 3 @pnnx_9=(64,64,1)f64 #3=(64,64,1)f64
nn.ZeroPad2d             backbone.body.0.0        1 1 0 4 padding=(0,1,0,1) #0=(1,3,256,256)f32 #4=(1,3,257,257)f32
nn.Conv2d                backbone.body.0.1        1 1 4 5 bias=True dilation=(1,1) groups=1 in_channels=3 kernel_size=(3,3) out_channels=32 padding=(0,0) padding_mode=zeros stride=(2,2) @bias=(32)f32 @weight=(32,3,3,3)f32 #4=(1,3,257,257)f32 #5=(1,32,128,128)f32
nn.ReLU6                 backbone.body.0.2        1 1 5 6 #5=(1,32,128,128)f32 #6=(1,32,128,128)f32
nn.Conv2d                backbone.body.1.conv.0.0 1 1 6 7 bias=True dilation=(1,1) groups=32 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,1,3,3)f32 #6=(1,32,128,128)f32 #7=(1,32,128,128)f32
nn.ReLU6                 backbone.body.1.conv.0.1 1 1 7 8 #7=(1,32,128,128)f32 #8=(1,32,128,128)f32
nn.Conv2d                backbone.body.1.conv.1   1 1 8 9 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(1,1) out_channels=16 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,32,1,1)f32 #8=(1,32,128,128)f32 #9=(1,16,128,128)f32
nn.Conv2d                backbone.body.2.conv.0.0 1 1 9 10 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,16,1,1)f32 #9=(1,16,128,128)f32 #10=(1,96,128,128)f32
nn.ReLU6                 backbone.body.2.conv.0.1 1 1 10 11 #10=(1,96,128,128)f32 #11=(1,96,128,128)f32
nn.ZeroPad2d             backbone.body.2.conv.1.0 1 1 11 12 padding=(0,1,0,1) #11=(1,96,128,128)f32 #12=(1,96,129,129)f32
nn.Conv2d                backbone.body.2.conv.1.1 1 1 12 13 bias=True dilation=(1,1) groups=96 in_channels=96 kernel_size=(3,3) out_channels=96 padding=(0,0) padding_mode=zeros stride=(2,2) @bias=(96)f32 @weight=(96,1,3,3)f32 #12=(1,96,129,129)f32 #13=(1,96,64,64)f32
nn.ReLU6                 backbone.body.2.conv.1.2 1 1 13 14 #13=(1,96,64,64)f32 #14=(1,96,64,64)f32
nn.Conv2d                backbone.body.2.conv.2   1 1 14 15 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=24 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,96,1,1)f32 #14=(1,96,64,64)f32 #15=(1,24,64,64)f32
nn.Conv2d                backbone.body.3.conv.0.0 1 1 15 16 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(1,1) out_channels=144 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(144)f32 @weight=(144,24,1,1)f32 #15=(1,24,64,64)f32 #16=(1,144,64,64)f32
nn.ReLU6                 backbone.body.3.conv.0.1 1 1 16 17 #16=(1,144,64,64)f32 #17=(1,144,64,64)f32
nn.Conv2d                backbone.body.3.conv.1.0 1 1 17 18 bias=True dilation=(1,1) groups=144 in_channels=144 kernel_size=(3,3) out_channels=144 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(144)f32 @weight=(144,1,3,3)f32 #17=(1,144,64,64)f32 #18=(1,144,64,64)f32
nn.ReLU6                 backbone.body.3.conv.1.1 1 1 18 19 #18=(1,144,64,64)f32 #19=(1,144,64,64)f32
nn.Conv2d                backbone.body.3.conv.2   1 1 19 20 bias=True dilation=(1,1) groups=1 in_channels=144 kernel_size=(1,1) out_channels=24 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,144,1,1)f32 #19=(1,144,64,64)f32 #20=(1,24,64,64)f32
BinaryOp                 add_0                    2 1 15 20 21 0=0 #15=(1,24,64,64)f32 #20=(1,24,64,64)f32 #21=(1,24,64,64)f32
nn.Conv2d                backbone.body.4.conv.0.0 1 1 21 22 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(1,1) out_channels=144 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(144)f32 @weight=(144,24,1,1)f32 #21=(1,24,64,64)f32 #22=(1,144,64,64)f32
nn.ReLU6                 backbone.body.4.conv.0.1 1 1 22 23 #22=(1,144,64,64)f32 #23=(1,144,64,64)f32
nn.ZeroPad2d             backbone.body.4.conv.1.0 1 1 23 24 padding=(0,1,0,1) #23=(1,144,64,64)f32 #24=(1,144,65,65)f32
nn.Conv2d                backbone.body.4.conv.1.1 1 1 24 25 bias=True dilation=(1,1) groups=144 in_channels=144 kernel_size=(3,3) out_channels=144 padding=(0,0) padding_mode=zeros stride=(2,2) @bias=(144)f32 @weight=(144,1,3,3)f32 #24=(1,144,65,65)f32 #25=(1,144,32,32)f32
nn.ReLU6                 backbone.body.4.conv.1.2 1 1 25 26 #25=(1,144,32,32)f32 #26=(1,144,32,32)f32
nn.Conv2d                backbone.body.4.conv.2   1 1 26 27 bias=True dilation=(1,1) groups=1 in_channels=144 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,144,1,1)f32 #26=(1,144,32,32)f32 #27=(1,32,32,32)f32
nn.Conv2d                backbone.body.5.conv.0.0 1 1 27 28 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(1,1) out_channels=192 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,32,1,1)f32 #27=(1,32,32,32)f32 #28=(1,192,32,32)f32
nn.ReLU6                 backbone.body.5.conv.0.1 1 1 28 29 #28=(1,192,32,32)f32 #29=(1,192,32,32)f32
nn.Conv2d                backbone.body.5.conv.1.0 1 1 29 30 bias=True dilation=(1,1) groups=192 in_channels=192 kernel_size=(3,3) out_channels=192 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,1,3,3)f32 #29=(1,192,32,32)f32 #30=(1,192,32,32)f32
nn.ReLU6                 backbone.body.5.conv.1.1 1 1 30 31 #30=(1,192,32,32)f32 #31=(1,192,32,32)f32
nn.Conv2d                backbone.body.5.conv.2   1 1 31 32 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,192,1,1)f32 #31=(1,192,32,32)f32 #32=(1,32,32,32)f32
BinaryOp                 add_1                    2 1 27 32 33 0=0 #27=(1,32,32,32)f32 #32=(1,32,32,32)f32 #33=(1,32,32,32)f32
nn.Conv2d                backbone.body.6.conv.0.0 1 1 33 34 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(1,1) out_channels=192 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,32,1,1)f32 #33=(1,32,32,32)f32 #34=(1,192,32,32)f32
nn.ReLU6                 backbone.body.6.conv.0.1 1 1 34 35 #34=(1,192,32,32)f32 #35=(1,192,32,32)f32
nn.Conv2d                backbone.body.6.conv.1.0 1 1 35 36 bias=True dilation=(1,1) groups=192 in_channels=192 kernel_size=(3,3) out_channels=192 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,1,3,3)f32 #35=(1,192,32,32)f32 #36=(1,192,32,32)f32
nn.ReLU6                 backbone.body.6.conv.1.1 1 1 36 37 #36=(1,192,32,32)f32 #37=(1,192,32,32)f32
nn.Conv2d                backbone.body.6.conv.2   1 1 37 38 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,192,1,1)f32 #37=(1,192,32,32)f32 #38=(1,32,32,32)f32
BinaryOp                 add_2                    2 1 33 38 39 0=0 #33=(1,32,32,32)f32 #38=(1,32,32,32)f32 #39=(1,32,32,32)f32
nn.Conv2d                backbone.body.7.conv.0.0 1 1 39 40 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(1,1) out_channels=192 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(192)f32 @weight=(192,32,1,1)f32 #39=(1,32,32,32)f32 #40=(1,192,32,32)f32
nn.ReLU6                 backbone.body.7.conv.0.1 1 1 40 41 #40=(1,192,32,32)f32 #41=(1,192,32,32)f32
nn.ZeroPad2d             backbone.body.7.conv.1.0 1 1 41 42 padding=(0,1,0,1) #41=(1,192,32,32)f32 #42=(1,192,33,33)f32
nn.Conv2d                backbone.body.7.conv.1.1 1 1 42 43 bias=True dilation=(1,1) groups=192 in_channels=192 kernel_size=(3,3) out_channels=192 padding=(0,0) padding_mode=zeros stride=(2,2) @bias=(192)f32 @weight=(192,1,3,3)f32 #42=(1,192,33,33)f32 #43=(1,192,16,16)f32
nn.ReLU6                 backbone.body.7.conv.1.2 1 1 43 44 #43=(1,192,16,16)f32 #44=(1,192,16,16)f32
nn.Conv2d                backbone.body.7.conv.2   1 1 44 45 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,192,1,1)f32 #44=(1,192,16,16)f32 #45=(1,64,16,16)f32
nn.Conv2d                backbone.body.8.conv.0.0 1 1 45 46 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=384 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(384)f32 @weight=(384,64,1,1)f32 #45=(1,64,16,16)f32 #46=(1,384,16,16)f32
nn.ReLU6                 backbone.body.8.conv.0.1 1 1 46 47 #46=(1,384,16,16)f32 #47=(1,384,16,16)f32
nn.Conv2d                backbone.body.8.conv.1.0 1 1 47 48 bias=True dilation=(1,1) groups=384 in_channels=384 kernel_size=(3,3) out_channels=384 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(384)f32 @weight=(384,1,3,3)f32 #47=(1,384,16,16)f32 #48=(1,384,16,16)f32
nn.ReLU6                 backbone.body.8.conv.1.1 1 1 48 49 #48=(1,384,16,16)f32 #49=(1,384,16,16)f32
nn.Conv2d                backbone.body.8.conv.2   1 1 49 50 bias=True dilation=(1,1) groups=1 in_channels=384 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,384,1,1)f32 #49=(1,384,16,16)f32 #50=(1,64,16,16)f32
BinaryOp                 add_3                    2 1 45 50 51 0=0 #45=(1,64,16,16)f32 #50=(1,64,16,16)f32 #51=(1,64,16,16)f32
nn.Conv2d                backbone.body.9.conv.0.0 1 1 51 52 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=384 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(384)f32 @weight=(384,64,1,1)f32 #51=(1,64,16,16)f32 #52=(1,384,16,16)f32
nn.ReLU6                 backbone.body.9.conv.0.1 1 1 52 53 #52=(1,384,16,16)f32 #53=(1,384,16,16)f32
nn.Conv2d                backbone.body.9.conv.1.0 1 1 53 54 bias=True dilation=(1,1) groups=384 in_channels=384 kernel_size=(3,3) out_channels=384 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(384)f32 @weight=(384,1,3,3)f32 #53=(1,384,16,16)f32 #54=(1,384,16,16)f32
nn.ReLU6                 backbone.body.9.conv.1.1 1 1 54 55 #54=(1,384,16,16)f32 #55=(1,384,16,16)f32
nn.Conv2d                backbone.body.9.conv.2   1 1 55 56 bias=True dilation=(1,1) groups=1 in_channels=384 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,384,1,1)f32 #55=(1,384,16,16)f32 #56=(1,64,16,16)f32
BinaryOp                 add_4                    2 1 51 56 57 0=0 #51=(1,64,16,16)f32 #56=(1,64,16,16)f32 #57=(1,64,16,16)f32
nn.Conv2d                backbone.body.10.conv.0.0 1 1 57 58 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=384 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(384)f32 @weight=(384,64,1,1)f32 #57=(1,64,16,16)f32 #58=(1,384,16,16)f32
nn.ReLU6                 backbone.body.10.conv.0.1 1 1 58 59 #58=(1,384,16,16)f32 #59=(1,384,16,16)f32
nn.Conv2d                backbone.body.10.conv.1.0 1 1 59 60 bias=True dilation=(1,1) groups=384 in_channels=384 kernel_size=(3,3) out_channels=384 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(384)f32 @weight=(384,1,3,3)f32 #59=(1,384,16,16)f32 #60=(1,384,16,16)f32
nn.ReLU6                 backbone.body.10.conv.1.1 1 1 60 61 #60=(1,384,16,16)f32 #61=(1,384,16,16)f32
nn.Conv2d                backbone.body.10.conv.2  1 1 61 62 bias=True dilation=(1,1) groups=1 in_channels=384 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,384,1,1)f32 #61=(1,384,16,16)f32 #62=(1,64,16,16)f32
BinaryOp                 add_5                    2 1 57 62 63 0=0 #57=(1,64,16,16)f32 #62=(1,64,16,16)f32 #63=(1,64,16,16)f32
nn.Conv2d                backbone.body.11.conv.0.0 1 1 63 64 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=384 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(384)f32 @weight=(384,64,1,1)f32 #63=(1,64,16,16)f32 #64=(1,384,16,16)f32
nn.ReLU6                 backbone.body.11.conv.0.1 1 1 64 65 #64=(1,384,16,16)f32 #65=(1,384,16,16)f32
nn.Conv2d                backbone.body.11.conv.1.0 1 1 65 66 bias=True dilation=(1,1) groups=384 in_channels=384 kernel_size=(3,3) out_channels=384 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(384)f32 @weight=(384,1,3,3)f32 #65=(1,384,16,16)f32 #66=(1,384,16,16)f32
nn.ReLU6                 backbone.body.11.conv.1.1 1 1 66 67 #66=(1,384,16,16)f32 #67=(1,384,16,16)f32
nn.Conv2d                backbone.body.11.conv.2  1 1 67 68 bias=True dilation=(1,1) groups=1 in_channels=384 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,384,1,1)f32 #67=(1,384,16,16)f32 #68=(1,96,16,16)f32
nn.Conv2d                backbone.body.12.conv.0.0 1 1 68 69 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=576 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(576)f32 @weight=(576,96,1,1)f32 #68=(1,96,16,16)f32 #69=(1,576,16,16)f32
nn.ReLU6                 backbone.body.12.conv.0.1 1 1 69 70 #69=(1,576,16,16)f32 #70=(1,576,16,16)f32
nn.Conv2d                backbone.body.12.conv.1.0 1 1 70 71 bias=True dilation=(1,1) groups=576 in_channels=576 kernel_size=(3,3) out_channels=576 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(576)f32 @weight=(576,1,3,3)f32 #70=(1,576,16,16)f32 #71=(1,576,16,16)f32
nn.ReLU6                 backbone.body.12.conv.1.1 1 1 71 72 #71=(1,576,16,16)f32 #72=(1,576,16,16)f32
nn.Conv2d                backbone.body.12.conv.2  1 1 72 73 bias=True dilation=(1,1) groups=1 in_channels=576 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,576,1,1)f32 #72=(1,576,16,16)f32 #73=(1,96,16,16)f32
BinaryOp                 add_6                    2 1 68 73 74 0=0 #68=(1,96,16,16)f32 #73=(1,96,16,16)f32 #74=(1,96,16,16)f32
nn.Conv2d                backbone.body.13.conv.0.0 1 1 74 75 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=576 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(576)f32 @weight=(576,96,1,1)f32 #74=(1,96,16,16)f32 #75=(1,576,16,16)f32
nn.ReLU6                 backbone.body.13.conv.0.1 1 1 75 76 #75=(1,576,16,16)f32 #76=(1,576,16,16)f32
nn.Conv2d                backbone.body.13.conv.1.0 1 1 76 77 bias=True dilation=(1,1) groups=576 in_channels=576 kernel_size=(3,3) out_channels=576 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(576)f32 @weight=(576,1,3,3)f32 #76=(1,576,16,16)f32 #77=(1,576,16,16)f32
nn.ReLU6                 backbone.body.13.conv.1.1 1 1 77 78 #77=(1,576,16,16)f32 #78=(1,576,16,16)f32
nn.Conv2d                backbone.body.13.conv.2  1 1 78 79 bias=True dilation=(1,1) groups=1 in_channels=576 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,576,1,1)f32 #78=(1,576,16,16)f32 #79=(1,96,16,16)f32
BinaryOp                 add_7                    2 1 74 79 80 0=0 #74=(1,96,16,16)f32 #79=(1,96,16,16)f32 #80=(1,96,16,16)f32
nn.Conv2d                backbone.body.14.conv.0.0 1 1 80 81 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=576 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(576)f32 @weight=(576,96,1,1)f32 #80=(1,96,16,16)f32 #81=(1,576,16,16)f32
nn.ReLU6                 backbone.body.14.conv.0.1 1 1 81 82 #81=(1,576,16,16)f32 #82=(1,576,16,16)f32
nn.ZeroPad2d             backbone.body.14.conv.1.0 1 1 82 83 padding=(0,1,0,1) #82=(1,576,16,16)f32 #83=(1,576,17,17)f32
nn.Conv2d                backbone.body.14.conv.1.1 1 1 83 84 bias=True dilation=(1,1) groups=576 in_channels=576 kernel_size=(3,3) out_channels=576 padding=(0,0) padding_mode=zeros stride=(2,2) @bias=(576)f32 @weight=(576,1,3,3)f32 #83=(1,576,17,17)f32 #84=(1,576,8,8)f32
nn.ReLU6                 backbone.body.14.conv.1.2 1 1 84 85 #84=(1,576,8,8)f32 #85=(1,576,8,8)f32
nn.Conv2d                backbone.body.14.conv.2  1 1 85 86 bias=True dilation=(1,1) groups=1 in_channels=576 kernel_size=(1,1) out_channels=160 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(160)f32 @weight=(160,576,1,1)f32 #85=(1,576,8,8)f32 #86=(1,160,8,8)f32
nn.Conv2d                backbone.body.15.conv.0.0 1 1 86 87 bias=True dilation=(1,1) groups=1 in_channels=160 kernel_size=(1,1) out_channels=960 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(960)f32 @weight=(960,160,1,1)f32 #86=(1,160,8,8)f32 #87=(1,960,8,8)f32
nn.ReLU6                 backbone.body.15.conv.0.1 1 1 87 88 #87=(1,960,8,8)f32 #88=(1,960,8,8)f32
nn.Conv2d                backbone.body.15.conv.1.0 1 1 88 89 bias=True dilation=(1,1) groups=960 in_channels=960 kernel_size=(3,3) out_channels=960 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(960)f32 @weight=(960,1,3,3)f32 #88=(1,960,8,8)f32 #89=(1,960,8,8)f32
nn.ReLU6                 backbone.body.15.conv.1.1 1 1 89 90 #89=(1,960,8,8)f32 #90=(1,960,8,8)f32
nn.Conv2d                backbone.body.15.conv.2  1 1 90 91 bias=True dilation=(1,1) groups=1 in_channels=960 kernel_size=(1,1) out_channels=160 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(160)f32 @weight=(160,960,1,1)f32 #90=(1,960,8,8)f32 #91=(1,160,8,8)f32
BinaryOp                 add_8                    2 1 86 91 92 0=0 #86=(1,160,8,8)f32 #91=(1,160,8,8)f32 #92=(1,160,8,8)f32
nn.Conv2d                backbone.body.16.conv.0.0 1 1 92 93 bias=True dilation=(1,1) groups=1 in_channels=160 kernel_size=(1,1) out_channels=960 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(960)f32 @weight=(960,160,1,1)f32 #92=(1,160,8,8)f32 #93=(1,960,8,8)f32
nn.ReLU6                 backbone.body.16.conv.0.1 1 1 93 94 #93=(1,960,8,8)f32 #94=(1,960,8,8)f32
nn.Conv2d                backbone.body.16.conv.1.0 1 1 94 95 bias=True dilation=(1,1) groups=960 in_channels=960 kernel_size=(3,3) out_channels=960 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(960)f32 @weight=(960,1,3,3)f32 #94=(1,960,8,8)f32 #95=(1,960,8,8)f32
nn.ReLU6                 backbone.body.16.conv.1.1 1 1 95 96 #95=(1,960,8,8)f32 #96=(1,960,8,8)f32
nn.Conv2d                backbone.body.16.conv.2  1 1 96 97 bias=True dilation=(1,1) groups=1 in_channels=960 kernel_size=(1,1) out_channels=160 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(160)f32 @weight=(160,960,1,1)f32 #96=(1,960,8,8)f32 #97=(1,160,8,8)f32
BinaryOp                 add_9                    2 1 92 97 98 0=0 #92=(1,160,8,8)f32 #97=(1,160,8,8)f32 #98=(1,160,8,8)f32
nn.Conv2d                backbone.body.17.conv.0.0 1 1 98 99 bias=True dilation=(1,1) groups=1 in_channels=160 kernel_size=(1,1) out_channels=960 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(960)f32 @weight=(960,160,1,1)f32 #98=(1,160,8,8)f32 #99=(1,960,8,8)f32
nn.ReLU6                 backbone.body.17.conv.0.1 1 1 99 100 #99=(1,960,8,8)f32 #100=(1,960,8,8)f32
nn.Conv2d                backbone.body.17.conv.1.0 1 1 100 101 bias=True dilation=(1,1) groups=960 in_channels=960 kernel_size=(3,3) out_channels=960 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(960)f32 @weight=(960,1,3,3)f32 #100=(1,960,8,8)f32 #101=(1,960,8,8)f32
nn.ReLU6                 backbone.body.17.conv.1.1 1 1 101 102 #101=(1,960,8,8)f32 #102=(1,960,8,8)f32
nn.Conv2d                backbone.body.17.conv.2  1 1 102 103 bias=True dilation=(1,1) groups=1 in_channels=960 kernel_size=(1,1) out_channels=320 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(320)f32 @weight=(320,960,1,1)f32 #102=(1,960,8,8)f32 #103=(1,320,8,8)f32
nn.Conv2d                backbone.body.18.0       1 1 103 104 bias=True dilation=(1,1) groups=1 in_channels=320 kernel_size=(1,1) out_channels=1280 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(1280)f32 @weight=(1280,320,1,1)f32 #103=(1,320,8,8)f32 #104=(1,1280,8,8)f32
nn.ReLU6                 backbone.body.18.1       1 1 104 105 #104=(1,1280,8,8)f32 #105=(1,1280,8,8)f32
nn.Conv2d                backbone.fpn.inner_blocks.3 1 1 105 106 bias=True dilation=(1,1) groups=1 in_channels=1280 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,1280,1,1)f32 #105=(1,1280,8,8)f32 #106=(1,64,8,8)f32
nn.Conv2d                backbone.fpn.inner_blocks.2 1 1 63 107 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,1,1)f32 #63=(1,64,16,16)f32 #107=(1,64,16,16)f32
F.upsample               F.upsample_2             1 1 106 108 align_corners=False mode=bilinear scale_factor=(2.000000e+00,2.000000e+00) $input=106 #106=(1,64,8,8)f32 #108=(1,64,16,16)f32
BinaryOp                 add_10                   2 1 107 108 109 0=0 #107=(1,64,16,16)f32 #108=(1,64,16,16)f32 #109=(1,64,16,16)f32
nn.Conv2d                backbone.fpn.layer_blocks.2.conv.0 1 1 109 110 bias=True dilation=(1,1) groups=64 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,1,3,3)f32 #109=(1,64,16,16)f32 #110=(1,64,16,16)f32
nn.Conv2d                backbone.fpn.layer_blocks.2.conv.1 1 1 110 111 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,64,1,1)f32 #110=(1,64,16,16)f32 #111=(1,32,16,16)f32
nn.ReLU                  backbone.fpn.layer_blocks.2.conv.2 1 1 111 112 #111=(1,32,16,16)f32 #112=(1,32,16,16)f32
nn.Conv2d                backbone.fpn.inner_blocks.1 1 1 39 113 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,1,1)f32 #39=(1,32,32,32)f32 #113=(1,32,32,32)f32
F.upsample               F.upsample_3             1 1 112 114 align_corners=False mode=bilinear scale_factor=(2.000000e+00,2.000000e+00) $input=112 #112=(1,32,16,16)f32 #114=(1,32,32,32)f32
BinaryOp                 add_11                   2 1 113 114 115 0=0 #113=(1,32,32,32)f32 #114=(1,32,32,32)f32 #115=(1,32,32,32)f32
nn.Conv2d                backbone.fpn.layer_blocks.1.conv.0 1 1 115 116 bias=True dilation=(1,1) groups=32 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,1,3,3)f32 #115=(1,32,32,32)f32 #116=(1,32,32,32)f32
nn.Conv2d                backbone.fpn.layer_blocks.1.conv.1 1 1 116 117 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(1,1) out_channels=24 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,32,1,1)f32 #116=(1,32,32,32)f32 #117=(1,24,32,32)f32
nn.ReLU                  backbone.fpn.layer_blocks.1.conv.2 1 1 117 118 #117=(1,24,32,32)f32 #118=(1,24,32,32)f32
nn.Conv2d                backbone.fpn.inner_blocks.0 1 1 21 119 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(1,1) out_channels=24 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,24,1,1)f32 #21=(1,24,64,64)f32 #119=(1,24,64,64)f32
F.upsample               F.upsample_4             1 1 118 120 align_corners=False mode=bilinear scale_factor=(2.000000e+00,2.000000e+00) $input=118 #118=(1,24,32,32)f32 #120=(1,24,64,64)f32
BinaryOp                 add_12                   2 1 119 120 121 0=0 #119=(1,24,64,64)f32 #120=(1,24,64,64)f32 #121=(1,24,64,64)f32
nn.Conv2d                backbone.fpn.layer_blocks.0.conv.0 1 1 121 122 bias=True dilation=(1,1) groups=24 in_channels=24 kernel_size=(3,3) out_channels=24 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,1,3,3)f32 #121=(1,24,64,64)f32 #122=(1,24,64,64)f32
nn.Conv2d                backbone.fpn.layer_blocks.0.conv.1 1 1 122 123 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(1,1) out_channels=24 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,24,1,1)f32 #122=(1,24,64,64)f32 #123=(1,24,64,64)f32
nn.ReLU                  backbone.fpn.layer_blocks.0.conv.2 1 1 123 124 #123=(1,24,64,64)f32 #124=(1,24,64,64)f32
nn.Conv2d                hm.0                     1 1 124 125 bias=True dilation=(1,1) groups=24 in_channels=24 kernel_size=(3,3) out_channels=24 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,1,3,3)f32 #124=(1,24,64,64)f32 #125=(1,24,64,64)f32
nn.Conv2d                hm.1                     1 1 125 126 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,24,1,1)f32 #125=(1,24,64,64)f32 #126=(1,96,64,64)f32
nn.ReLU                  hm.2                     1 1 126 127 #126=(1,96,64,64)f32 #127=(1,96,64,64)f32
nn.Conv2d                hm.3                     1 1 127 128 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=1 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(1)f32 @weight=(1,96,1,1)f32 #127=(1,96,64,64)f32 #128=(1,1,64,64)f32
nn.Conv2d                hps.0                    1 1 124 129 bias=True dilation=(1,1) groups=24 in_channels=24 kernel_size=(3,3) out_channels=24 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,1,3,3)f32 #124=(1,24,64,64)f32 #129=(1,24,64,64)f32
nn.Conv2d                hps.1                    1 1 129 130 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,24,1,1)f32 #129=(1,24,64,64)f32 #130=(1,96,64,64)f32
nn.ReLU                  hps.2                    1 1 130 131 #130=(1,96,64,64)f32 #131=(1,96,64,64)f32
nn.Conv2d                hps.3                    1 1 131 132 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=34 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(34)f32 @weight=(34,96,1,1)f32 #131=(1,96,64,64)f32 #132=(1,34,64,64)f32
nn.Conv2d                hm_hp.0                  1 1 124 133 bias=True dilation=(1,1) groups=24 in_channels=24 kernel_size=(3,3) out_channels=24 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,1,3,3)f32 #124=(1,24,64,64)f32 #133=(1,24,64,64)f32
nn.Conv2d                hm_hp.1                  1 1 133 134 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,24,1,1)f32 #133=(1,24,64,64)f32 #134=(1,96,64,64)f32
nn.ReLU                  hm_hp.2                  1 1 134 135 #134=(1,96,64,64)f32 #135=(1,96,64,64)f32
nn.Conv2d                hm_hp.3                  1 1 135 136 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=17 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(17)f32 @weight=(17,96,1,1)f32 #135=(1,96,64,64)f32 #136=(1,17,64,64)f32
nn.Conv2d                hp_offset.0              1 1 124 137 bias=True dilation=(1,1) groups=24 in_channels=24 kernel_size=(3,3) out_channels=24 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(24)f32 @weight=(24,1,3,3)f32 #124=(1,24,64,64)f32 #137=(1,24,64,64)f32
nn.Conv2d                hp_offset.1              1 1 137 138 bias=True dilation=(1,1) groups=1 in_channels=24 kernel_size=(1,1) out_channels=96 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(96)f32 @weight=(96,24,1,1)f32 #137=(1,24,64,64)f32 #138=(1,96,64,64)f32
nn.ReLU                  hp_offset.2              1 1 138 139 #138=(1,96,64,64)f32 #139=(1,96,64,64)f32
nn.Conv2d                hp_offset.3              1 1 139 140 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=34 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(34)f32 @weight=(34,96,1,1)f32 #139=(1,96,64,64)f32 #140=(1,34,64,64)f32
torch.squeeze            torch.squeeze_33         1 1 128 141 dim=0 $input=128 #128=(1,1,64,64)f32 #141=(1,64,64)f32
torch.permute            torch.permute_28         1 1 141 142 dims=(1,2,0) $input=141 #141=(1,64,64)f32 #142=(64,64,1)f32
F.sigmoid                F.sigmoid_1              1 1 142 143 $input=142 #142=(64,64,1)f32 #143=(64,64,1)f32
BinaryOp                 mul_13                   2 1 143 3 144 0=2 #143=(64,64,1)f32 #3=(64,64,1)f64 #144=(64,64,1)f64
Tensor.view              Tensor.view_14           1 1 144 145 shape=(1,4096,1) $input=144 #144=(64,64,1)f64 #145=(1,4096,1)f64
torch.argmax             torch.argmax_18          1 1 145 146 dim=1 keepdim=False $input=145 #145=(1,4096,1)f64 #146=(1,1)i64
BinaryOp                 div_14                   1 1 146 147 0=3 1=1 2=4.800000e+01 #146=(1,1)i64 #147=(1,1)i64
BinaryOp                 mul_15                   1 1 147 148 0=2 1=1 2=4.800000e+01 #147=(1,1)i64
BinaryOp                 sub_16                   2 1 146 148 149 0=1 #146=(1,1)i64 #149=(1,1)i64
torch.unsqueeze          torch.unsqueeze_39       1 1 146 150 dim=2 $input=146 #146=(1,1)i64 #150=(1,1,1)i64
Tensor.repeat            Tensor.repeat_5          1 1 150 151 sizes=(1,17,2) $input=150 #150=(1,1,1)i64 #151=(1,17,2)i64
torch.squeeze            torch.squeeze_34         1 1 132 152 dim=0 $input=132 #132=(1,34,64,64)f32 #152=(34,64,64)f32
torch.permute            torch.permute_29         1 1 152 153 dims=(1,2,0) $input=152 #152=(34,64,64)f32 #153=(64,64,34)f32
Tensor.view              Tensor.view_15           1 1 153 154 shape=(-1,17,2) $input=153 #153=(64,64,34)f32 #154=(4096,17,2)f32
torch.gather             torch.gather_24          2 1 154 151 155 dim=0 $input=154 $index=151 #154=(4096,17,2)f32 #151=(1,17,2)i64 #155=(1,17,2)f32
torch.cat                torch.cat_20             2 1 147 149 156 dim=1 #147=(1,1)i64 #149=(1,1)i64 #156=(1,2)i64
torch.squeeze            torch.squeeze_36         1 1 155 157 dim=0 $input=155 #155=(1,17,2)f32 #157=(17,2)f32
BinaryOp                 add_17                   2 1 157 156 158 0=0 #157=(17,2)f32 #156=(1,2)i64 #158=(17,2)f32
torch.unbind             Tensor.select_10         1 2 158 159 160 dim=1 #158=(17,2)f32 #159=(17)f32 #160=(17)f32
Tensor.reshape           Tensor.reshape_6         1 1 159 161 shape=(1,1,17) $input=159 #159=(17)f32 #161=(1,1,17)f32
BinaryOp                 sub_18                   2 1 2 161 162 0=1 #2=(64,64,1)f32 #161=(1,1,17)f32 #162=(64,64,17)f32
Tensor.reshape           Tensor.reshape_7         1 1 160 163 shape=(1,1,17) $input=160 #160=(17)f32 #163=(1,1,17)f32
BinaryOp                 sub_19                   2 1 1 163 164 0=1 #1=(64,64,1)f32 #163=(1,1,17)f32 #164=(64,64,17)f32
torch.squeeze            torch.squeeze_32         1 1 136 165 dim=0 $input=136 #136=(1,17,64,64)f32 #165=(17,64,64)f32
torch.permute            torch.permute_27         1 1 165 166 dims=(1,2,0) $input=165 #165=(17,64,64)f32 #166=(64,64,17)f32
F.sigmoid                F.sigmoid_0              1 1 166 167 $input=166 #166=(64,64,17)f32 #167=(64,64,17)f32
BinaryOp                 mul_20                   2 1 164 164 168 0=2 #164=(64,64,17)f32 #164=(64,64,17)f32
BinaryOp                 mul_21                   2 1 162 162 169 0=2 #162=(64,64,17)f32 #162=(64,64,17)f32
BinaryOp                 add_22                   2 1 169 168 170 0=0
UnaryOp                  sqrt_23                  1 1 170 171 0=5
BinaryOp                 add_24                   1 1 171 172 0=0 1=1 2=1.800000e+00
BinaryOp                 div_25                   2 1 167 172 173 0=3 #167=(64,64,17)f32 #173=(64,64,17)f32
Tensor.reshape           Tensor.reshape_8         1 1 173 174 shape=(1,4096,17) $input=173 #173=(64,64,17)f32 #174=(1,4096,17)f32
torch.argmax             torch.argmax_19          1 1 174 175 dim=1 keepdim=False $input=174 #174=(1,4096,17)f32 #175=(1,17)i64
BinaryOp                 div_26                   1 1 175 176 0=3 1=1 2=6.400000e+01 #175=(1,17)i64 #176=(1,17)i64
BinaryOp                 mul_27                   1 1 176 177 0=2 1=1 2=6.400000e+01 #176=(1,17)i64
BinaryOp                 sub_28                   2 1 175 177 178 0=1 #175=(1,17)i64 #178=(1,17)i64
torch.cat                torch.cat_21             2 1 176 178 179 dim=0 #176=(1,17)i64 #178=(1,17)i64 #179=(2,17)i64
Tensor.view              Tensor.view_16           1 1 167 180 shape=(-1,17) $input=167 #167=(64,64,17)f32 #180=(4096,17)f32
torch.gather             torch.gather_25          2 1 180 175 181 dim=0 $input=180 $index=175 #180=(4096,17)f32 #175=(1,17)i64 #181=(1,17)f32
torch.unsqueeze          torch.unsqueeze_40       1 1 175 182 dim=-1 $input=175 #175=(1,17)i64 #182=(1,17,1)i64
torch.squeeze            torch.squeeze_35         1 1 140 183 dim=0 $input=140 #140=(1,34,64,64)f32 #183=(34,64,64)f32
torch.permute            torch.permute_30         1 1 183 184 dims=(1,2,0) $input=183 #183=(34,64,64)f32 #184=(64,64,34)f32
Tensor.view              Tensor.view_17           1 1 184 185 shape=(-1,17,2) $input=184 #184=(64,64,34)f32 #185=(4096,17,2)f32
torch.cat                torch.cat_22             2 1 182 182 186 dim=-1 #182=(1,17,1)i64 #182=(1,17,1)i64 #186=(1,17,2)i64
torch.gather             torch.gather_26          2 1 185 186 187 dim=0 $input=185 $index=186 #185=(4096,17,2)f32 #186=(1,17,2)i64 #187=(1,17,2)f32
torch.permute            torch.permute_31         1 1 179 188 dims=(1,0) $input=179 #179=(2,17)i64 #188=(17,2)i64
torch.squeeze            torch.squeeze_38         1 1 187 189 dim=0 $input=187 #187=(1,17,2)f32 #189=(17,2)f32
BinaryOp                 add_29                   2 1 189 188 190 0=0 #189=(17,2)f32 #188=(17,2)i64
BinaryOp                 div_30                   1 1 190 191 0=3 1=1 2=6.400000e+01 #191=(17,2)f32
torch.squeeze            torch.squeeze_37         1 1 181 192 dim=0 $input=181 #181=(1,17)f32 #192=(17)f32
torch.unsqueeze          torch.unsqueeze_41       1 1 192 193 dim=1 $input=192 #192=(17)f32 #193=(17,1)f32
torch.cat                torch.cat_23             2 1 191 193 194 dim=1 #191=(17,2)f32 #193=(17,1)f32 #194=(17,3)f32
Tensor.reshape           Tensor.reshape_9         1 1 194 195 shape=(1,1,17,3) $input=194 #194=(17,3)f32 #195=(1,1,17,3)f32
pnnx.Output              pnnx_output_0            1 0 195 #195=(1,1,17,3)f32
